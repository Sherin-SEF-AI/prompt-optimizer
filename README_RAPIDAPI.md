# LLM Prompt Optimizer - RapidAPI

A comprehensive framework for systematic A/B testing and optimization of LLM prompts

## Quick Start

### 1. Subscribe to the API
Visit the [RapidAPI marketplace](https://rapidapi.com) and subscribe to the LLM Prompt Optimizer API.

### 2. Get Your API Key
After subscribing, you'll receive your RapidAPI key.

### 3. Make Your First Request

```bash
curl --request GET \
  --url https://llm-prompt-optimizer.p.rapidapi.com/health \
  --header 'X-RapidAPI-Key: YOUR_API_KEY' \
  --header 'X-RapidAPI-Host: llm-prompt-optimizer.p.rapidapi.com'
```

## API Documentation

- **Interactive Docs**: https://llm-prompt-optimizer.p.rapidapi.com/docs
- **OpenAPI Spec**: https://llm-prompt-optimizer.p.rapidapi.com/openapi.json
- **GitHub**: https://github.com/Sherin-SEF-AI/prompt-optimizer
- **PyPI**: https://pypi.org/project/llm-prompt-optimizer

## Support

- **Email**: sherin.joseph2217@gmail.com
- **GitHub Issues**: https://github.com/Sherin-SEF-AI/prompt-optimizer/issues
- **Documentation**: https://github.com/Sherin-SEF-AI/prompt-optimizer/blob/main/README.md

## License

MIT License - see https://github.com/Sherin-SEF-AI/prompt-optimizer/blob/main/LICENSE for details.
